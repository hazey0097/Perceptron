# -*- coding: utf-8 -*-
"""Perceptron Lab - Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c2Y9p7x54LO9-DRkiAhXyX9C0x6nXcTn
"""

pip install arff

## IMPORTS 
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.linear_model import Perceptron
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import arff
import random
import pandas as pd 
import copy

"""Perceptron with no stopping criteria"""

class PerceptronClassifier(BaseEstimator,ClassifierMixin):

  def __init__(self, lr=.1, shuffle=True):
      self.lr = lr
      self.shuffle = shuffle
      self.bias_weight = 0
      
  def fit(self, X, y, initial_weights=None):
    self.num_inputs = len(X[0]) # init the number of inputs
    self.num_weights = self.num_inputs # init the number of weight needed for inputs 

    self.weights = self.initialize_weights() if not initial_weights else initial_weights
    self.weights.append(self.bias_weight)

    for i in range(10): #while(self.last_update <= 5):

      for t_value_index in range(len(y)):
        t_value = y[t_value_index]
        row_index = t_value_index
        net_value = self.get_net_value(X[row_index])

        z_value = 0 # actual output value produced by the perceptron
        if net_value > 0:
          z_value = 1

        change_in_weights = []
        for column_index in range(self.num_inputs): # iterate over each value in the current input row
          change_in_weights.append(self.calculate_change_in_weight(t_value, z_value,X[row_index][column_index]))
        self.weights = [a + b for a, b in zip(self.weights, change_in_weights)]

    return self

  def calculate_change_in_weight(self, t_value, z_value, input_value):
    return self.lr *(t_value - z_value) * input_value 

  def get_net_value(self, X):
    net_value = 0
    for i in range(self.num_inputs):
      net_value += (X[i] * self.weights[i])
    return net_value 
        
  def predict(self, X):
    predictions = [] 
    for row_index in range(len(X)):
      net_value = self.get_net_value(X[row_index])
      predictions.append(1 if net_value > 0 else 0)
    return predictions

  def initialize_weights(self):
      return [0] * (self.num_weights - 1)

  def score(self, X, y):
    predictions = self.predict(X)
    correct_classification = 0
    for i in range(len(predictions)):
      if predictions[i] == y[i]:
        correct_classification += 1
    self.accuracy = correct_classification / len(X)
    return self.accuracy

  def _shuffle_data(self, X, y):
    temp_data = copy.deepcopy(X)
    temp_targets = copy.deepcopy(y)
    for row in range(len(temp_data)):
      temp_data[row].append(temp_targets[row])
    random.shuffle(temp_data)
    shuffled_data = [row[:-1] for row in temp_data]
    shuffled_targets = [row[-1] for row in temp_data]

    return shuffled_data, shuffled_targets

  ### Not required by sk-learn but required by us for grading. Returns the weights.
  def get_weights(self):
      return self.weights

  def split_data(self, X, y):
    shuffled_data, shuffled_targets = self._shuffle_data(X,y)
    training_percentage = 0.7 * len(X)
    train_data = shuffled_data[:round(training_percentage)]
    test_data = huffled_data[round(training_percentage):]
    return train_data, test_data

"""Evaluation Set with 10 Epochs"""

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/data_banknote_authentication.arff')
data = []
labels = []

for row in mat[0]:
  temp = list(row.item()[:-1])
  temp.append(1)
  data.append(temp)
  labels.append(int(row.item()[-1].decode()))

PClass = PerceptronClassifier(lr=0.1,shuffle=False)
PClass.fit(data,labels)

Accuracy = PClass.score(data,labels)
print("Accuray = [{:.2f}]".format(Accuracy))
print("Final Weights =",PClass.get_weights())
shuffled_data, shuffled_targets = PClass._shuffle_data(data,labels)
print("--------------------------------")

"""Debug Set with 10 Epochs"""

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/linsep2nonorigin.arff')
data = []
labels = []

for row in mat[0]:
  temp = list(row.item()[:-1])
  temp.append(1)
  data.append(temp)
  labels.append(int(row.item()[-1].decode()))

PClass = PerceptronClassifier(lr=0.1,shuffle=False)
PClass.fit(data,labels)
Accuracy = PClass.score(data,labels)
print("Accuray = [{:.2f}]".format(Accuracy))
print("Final Weights =",PClass.get_weights())
print("--------------------------------")

"""Perceptron with stopping criteria """

class PerceptronClassifierWithStoppingCriteria(BaseEstimator,ClassifierMixin):

  def __init__(self, lr=.1, shuffle=True):
      self.lr = lr
      self.shuffle = shuffle
      self.bias_weight = 0
      self.epoch_number = 0
      
  def fit(self, X, y, initial_weights=None):
    self.num_inputs = len(X[0]) # init the number of inputs
    self.num_weights = self.num_inputs # init the number of weight needed for inputs 

    self.last_update = 0
    self.epoch_last_update = 0
    self.best_weights_so_far = []
    self.best_accuracy_so_far = 0
    self.epoch_misclassifcation = []
    

    self.weights = self.initialize_weights() if not initial_weights else initial_weights
    self.weights.append(self.bias_weight)

    while(self.epoch_last_update <= 5):
      
      for t_value_index in range(len(y)):
        self.misclassification_rates = []
        t_value = y[t_value_index]
        row_index = t_value_index
        net_value = self.get_net_value(X[row_index])

        z_value = 0 # actual output value produced by the perceptron
        if net_value > 0:
          z_value = 1

        change_in_weights = []
        for column_index in range(self.num_inputs): # iterate over each value in the current input row
          change_in_weights.append(self.calculate_change_in_weight(t_value, z_value,X[row_index][column_index]))
          
        self.weights = [a + b for a, b in zip(self.weights, change_in_weights)]

        temp_accuracy = self.score(X, y)
        
        if temp_accuracy > self.best_accuracy_so_far:
          self.best_weights_so_far = self.weights[:]
          self.best_accuracy_so_far = temp_accuracy
          self.last_update = 0 ## start counting from zero again
        else:
          self.last_update += 1
        self.misclassification_rates.append(self.misclassification / len(X))        
      self.epoch_misclassifcation.append(sum(self.misclassification_rates)/len(self.misclassification_rates))

      self.epoch_number += 1
      self.epoch_last_update = self.last_update / len(X)

      if self.shuffle == True:
        X,y = self._shuffle_data(X,y)

    self.weights = self.best_weights_so_far[:]
    
    return self

  def calculate_change_in_weight(self, t_value, z_value, input_value):
    return self.lr *(t_value - z_value) * input_value 

  def get_net_value(self, X):
    net_value = 0
    for i in range(self.num_inputs):
      net_value += (X[i] * self.weights[i])
    return net_value 
        
  def predict(self, X):
    predictions = [] 
    for row_index in range(len(X)):
      net_value = self.get_net_value(X[row_index])
      predictions.append(1 if net_value > 0 else 0)
    return predictions

  def initialize_weights(self):
      return [0] * (self.num_weights - 1)

  def score(self, X, y):
    predictions = self.predict(X)
    self.correct_classification = 0
    self.misclassification = 0
    for i in range(len(predictions)):
      if predictions[i] == y[i]:
        self.correct_classification += 1
      else:
        self.misclassification += 1
    self.accuracy = self.correct_classification / len(X)
    return self.accuracy

  def _shuffle_data(self, X, y):
    temp_data = copy.deepcopy(X)
    temp_targets = copy.deepcopy(y)
    for row in range(len(temp_data)):
      temp_data[row].append(temp_targets[row])
    random.shuffle(temp_data)
    shuffled_data = [row[:-1] for row in temp_data]
    shuffled_targets = [row[-1] for row in temp_data]

    return shuffled_data, shuffled_targets

  ### Not required by sk-learn but required by us for grading. Returns the weights.
  def get_weights(self):
      return self.weights
  
  def split_data(self, X, y):
      shuffled_data, shuffled_targets = self._shuffle_data(X,y)
      training_percentage = 0.7 * len(shuffled_data)
      train_data = shuffled_data[:round(training_percentage)]
      test_data = shuffled_data[round(training_percentage):]
      train_targets = shuffled_targets[:round(training_percentage)]
      test_targets = shuffled_targets[round(training_percentage):]
      return train_data, test_data, train_targets, test_targets

"""Evaluation Set with Stopping Criteria Perceptron"""

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/data_banknote_authentication.arff')
data = []
labels = []

for row in mat[0]:
  temp = list(row.item()[:-1])
  temp.append(1)
  data.append(temp)
  labels.append(int(row.item()[-1].decode()))

PClass_2 = PerceptronClassifierWithStoppingCriteria(lr=0.1,shuffle=False)
PClass_2.fit(data,labels)
print("Data:")
print(data)
print("--------------------------------")
print("labels:")
print(labels)
print("--------------------------------")
Accuracy = PClass_2.score(data,labels)
print("Accuray = [{:.2f}]".format(Accuracy))
print("Final Weights =",PClass_2.get_weights())

"""Part 2-4: Creating Personal Data Sets"""

def graph_data(X,weights, title):
  slope = -weights[0]/weights[1]
  intercept = -weights[2]/weights[1]
  x_axis= [row[0] for row in X]
  y_axis = [row[1] for row in X]
  plt.scatter(x_axis[:4], y_axis[:4], color ='red')
  plt.scatter(x_axis[4:], y_axis[4:], color ='blue')
  plt.xlabel('X axis', color='#1C2833')
  plt.ylabel('Y axis', color='#1C2833')
  x_axis = np.linspace(x_axis, len(x_axis))
  linear_equation = slope * x_axis + intercept 
  plt.plot(x_axis, linear_equation, color='green')
  plt.xlim([-.25, 1.1])
  plt.grid()
  plt.title(title)

# Linearly Seperable Data Set
data = pd.read_csv("/content/drive/MyDrive/CS 472 Files/Perceptron Lab/linearly_seperable_data.csv") 
inputs = []
targets = []
for i in data.iloc:
  inputs.append([i[0],i[1],1])
  targets.append(i[-1])
print(targets)
PClass_2 = PerceptronClassifierWithStoppingCriteria(lr=0.0001,shuffle=False)
PClass_2.fit(inputs,targets)
Accuracy = PClass_2.score(inputs,targets)
print("Number of epochs: " + str(PClass_2.epoch_number))
print("Accuray = [{:.2f}]".format(Accuracy))
print("Final Weights =",PClass_2.get_weights())
graph_data(inputs,PClass_2.get_weights(),"Linearly Seperable Data")

# Non Linearly Seperable Data Set
data = pd.read_csv("/content/drive/MyDrive/CS 472 Files/Perceptron Lab/non_linear_seperable_data.csv") 
inputs = []
targets = []
for i in data.iloc:
  inputs.append([i[0],i[1],1])
  targets.append(i[-1])
print(targets)
print("Number of epochs: " + str(PClass_2.epoch_number))
PClass_2 = PerceptronClassifierWithStoppingCriteria(lr=0.01,shuffle=False)
PClass_2.fit(inputs,targets)
Accuracy = PClass_2.score(inputs,targets)
print("Accuray = [{:.2f}]".format(Accuracy))
print("Final Weights =",PClass_2.get_weights())
graph_data(inputs,PClass_2.get_weights(),"Non Linearly Seperable Data")

"""Part 5:  Voting Set """

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/voting-dataset.arff')
data = []
labels = []

def convert_row_to_binary(X):
  new_row = []
  for i in X:
    if i.decode() == 'n':
      new_row.append(0)
    elif i.decode() == 'y':
      new_row.append(1)
    elif i.decode() == 'democrat':
      new_row.append(0)
    elif i.decode() == 'republican':
      new_row.append(1)
  return new_row


for row in mat[0]:
  temp = list(row.item()[:-1])
  temp = convert_row_to_binary(temp)
  temp.append(1)
  data.append(temp)
  labels.append(row.item()[-1])
labels = convert_row_to_binary(labels)


for i in range(5):
  PClass_2 = PerceptronClassifierWithStoppingCriteria(lr=0.1,shuffle=True)
  training_data, testing_data, training_targets, testing_targets = PClass_2.split_data(data,labels)
  PClass_2.fit(training_data,training_targets)
  print("Train Accuracy = [{:.2f}]".format(PClass_2.best_accuracy_so_far))
  Accuracy = PClass_2.score(testing_data,testing_targets)
  print("Accuray = [{:.2f}]".format(Accuracy))
  print("Number of epochs: " + str(PClass_2.epoch_number))
  print("Weights: " + str(PClass_2.get_weights()))
  print("Correct Classifcation:" + str(PClass_2.correct_classification))
  print("Wrong Classifcation:" + str(PClass_2.epoch_misclassifcation))
  print("---------------------------------------------------------")

"""Part 6: Scikit-Learning Tool Voting Set"""

from sklearn.datasets import load_digits
from sklearn.linear_model import Perceptron

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/voting-dataset.arff')
data = []
labels = []

def convert_row_to_binary(X):
  new_row = []
  for i in X:
    if i.decode() == 'n':
      new_row.append(0)
    elif i.decode() == 'y':
      new_row.append(1)
    elif i.decode() == 'democrat':
      new_row.append(0)
    elif i.decode() == 'republican':
      new_row.append(1)
  return new_row


for row in mat[0]:
  temp = list(row.item()[:-1])
  temp = convert_row_to_binary(temp)
  temp.append(1)
  data.append(temp)
  labels.append(row.item()[-1])
labels = convert_row_to_binary(labels)

for i in range(5):
  clf = Perceptron(tol=1e-3, random_state=i)
  clf.fit(data, labels)
  Perceptron()
  print(clf.score(data, labels))

#print("with early stopping")
#for i in range(5):
  #clf = Perceptron(tol=1e-3, random_state=i, early_stopping=True)
  #clf.fit(data, labels)
  #Perceptron()
  #print(clf.score(data, labels))

#print("with shuffle")
#for i in range(5):
 #clf = Perceptron(tol=1e-3, random_state=i,shuffle=True)
  #clf.fit(data, labels)
  #Perceptron()
  #print(clf.score(data, labels))

"""Part 6: Scikit Perceptron cmp1_rep dataset"""

from sklearn.datasets import load_digits
from sklearn.linear_model import Perceptron

mat = arff.loadarff('/content/drive/MyDrive/CS 472 Files/Perceptron Lab/cm1_req.arff.txt')
data = []
labels = []

def convert_row_to_binary(X):
  new_row = []
  for i in X:
    if type(i)== float:
        new_row.append(i)
    else:
      if i.decode() == 'Y':
        new_row.append(1)
      elif i.decode() == 'N':
        new_row.append(0)
      else:
          new_row.append(int(i.decode()))
  return new_row


for row in mat[0]:
  temp = list(row.item()[:-1])
  temp = convert_row_to_binary(temp)
  temp.append(1)
  data.append(temp)
  labels.append(row.item()[-1])
labels = convert_row_to_binary(labels)

for i in range(5):
  clf = Perceptron(tol=1e-3, random_state=i)
  clf.fit(data, labels)
  Perceptron()
  print(clf.score(data, labels))

#print("with early stopping")
#for i in range(5):
  #clf = Perceptron(tol=1e-3, random_state=i, early_stopping=True)
  #clf.fit(data, labels)
  #Perceptron()
  #print(clf.score(data, labels))

#print("with shuffle")
#for i in range(5):
 #clf = Perceptron(tol=1e-3, random_state=i,shuffle=True)
  #clf.fit(data, labels)
  #Perceptron()
  #print(clf.score(data, labels))

#My Perceptron 
for i in range(5):
  PClass_2 = PerceptronClassifierWithStoppingCriteria(lr=0.1,shuffle=True)
  training_data, testing_data, training_targets, testing_targets = PClass_2.split_data(data,labels)
  PClass_2.fit(training_data,training_targets)
  print("Train Accuracy = [{:.2f}]".format(PClass_2.best_accuracy_so_far))
  Accuracy = PClass_2.score(testing_data,testing_targets)
  print("Accuray = [{:.2f}]".format(Accuracy))
  print("---------------------------------------------------------")